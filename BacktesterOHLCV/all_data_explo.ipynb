{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29fd658e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-22 00:48:02,214 - WARNING - Skipping FPLPF.csv: More than 10% of 'Volume' values are zero or missing.\n",
      "2025-04-22 00:48:02,487 - WARNING - Skipping KGNR.csv: More than 10% of 'Volume' values are zero or missing.\n",
      "2025-04-22 00:48:02,487 - WARNING - Skipping KGNR.csv: More than 10% of 'Volume' values are zero or missing.\n",
      "2025-04-22 00:48:02,744 - WARNING - Skipping NOXL.csv: More than 10% of 'Volume' values are zero or missing.\n",
      "2025-04-22 00:48:02,744 - WARNING - Skipping NOXL.csv: More than 10% of 'Volume' values are zero or missing.\n",
      "2025-04-22 00:48:02,868 - WARNING - Skipping UEEC.csv: More than 10% of 'Volume' values are zero or missing.\n",
      "2025-04-22 00:48:02,868 - WARNING - Skipping UEEC.csv: More than 10% of 'Volume' values are zero or missing.\n",
      "2025-04-22 00:48:03,239 - WARNING - Skipping WSPOF.csv: More than 10% of 'Volume' values are zero or missing.\n",
      "2025-04-22 00:48:03,239 - WARNING - Skipping WSPOF.csv: More than 10% of 'Volume' values are zero or missing.\n",
      "2025-04-22 00:48:03,425 - WARNING - Skipping TCYSF.csv: More than 10% of 'Volume' values are zero or missing.\n",
      "2025-04-22 00:48:03,425 - WARNING - Skipping TCYSF.csv: More than 10% of 'Volume' values are zero or missing.\n",
      "2025-04-22 00:48:03,773 - WARNING - Skipping NCTKF.csv: More than 10% of 'Volume' values are zero or missing.\n",
      "2025-04-22 00:48:03,773 - WARNING - Skipping NCTKF.csv: More than 10% of 'Volume' values are zero or missing.\n",
      "2025-04-22 00:48:04,193 - WARNING - Skipping XLEFF.csv: More than 10% of 'Volume' values are zero or missing.\n",
      "2025-04-22 00:48:04,193 - WARNING - Skipping XLEFF.csv: More than 10% of 'Volume' values are zero or missing.\n",
      "2025-04-22 00:48:04,242 - WARNING - Skipping RXMD.csv: More than 10% of 'Volume' values are zero or missing.\n",
      "2025-04-22 00:48:04,242 - WARNING - Skipping RXMD.csv: More than 10% of 'Volume' values are zero or missing.\n",
      "2025-04-22 00:48:04,312 - WARNING - Skipping CTQ.csv: More than 20% of 'Adjusted Close' values are zero or missing.\n",
      "2025-04-22 00:48:04,312 - WARNING - Skipping CTQ.csv: More than 20% of 'Adjusted Close' values are zero or missing.\n",
      "2025-04-22 00:48:04,678 - WARNING - Skipping BHI.csv: More than 20% of 'Adjusted Close' values are zero or missing.\n",
      "2025-04-22 00:48:04,678 - WARNING - Skipping BHI.csv: More than 20% of 'Adjusted Close' values are zero or missing.\n",
      "2025-04-22 00:48:04,718 - WARNING - Skipping SEGXF.csv: More than 10% of 'Volume' values are zero or missing.\n",
      "2025-04-22 00:48:04,718 - WARNING - Skipping SEGXF.csv: More than 10% of 'Volume' values are zero or missing.\n",
      "2025-04-22 00:48:04,751 - WARNING - Skipping NMHLY.csv: More than 10% of 'Volume' values are zero or missing.\n",
      "2025-04-22 00:48:04,756 - WARNING - Skipping KACPF.csv: At least one 'Adjusted Close' value is negative.\n",
      "2025-04-22 00:48:04,751 - WARNING - Skipping NMHLY.csv: More than 10% of 'Volume' values are zero or missing.\n",
      "2025-04-22 00:48:04,756 - WARNING - Skipping KACPF.csv: At least one 'Adjusted Close' value is negative.\n",
      "2025-04-22 00:48:04,851 - WARNING - Skipping BMRA.csv: More than 10% of 'Volume' values are zero or missing.\n",
      "2025-04-22 00:48:04,851 - WARNING - Skipping BMRA.csv: More than 10% of 'Volume' values are zero or missing.\n",
      "2025-04-22 00:48:04,988 - WARNING - Skipping FRMC.csv: More than 10% of 'Volume' values are zero or missing.\n",
      "2025-04-22 00:48:04,988 - WARNING - Skipping FRMC.csv: More than 10% of 'Volume' values are zero or missing.\n",
      "2025-04-22 00:48:05,060 - WARNING - Skipping INTH.csv: More than 10% of 'Volume' values are zero or missing.\n",
      "2025-04-22 00:48:05,060 - WARNING - Skipping INTH.csv: More than 10% of 'Volume' values are zero or missing.\n",
      "2025-04-22 00:48:05,744 - WARNING - Skipping RSNHF.csv: At least one 'Adjusted Close' value is negative.\n",
      "2025-04-22 00:48:05,753 - WARNING - Skipping TRAUF.csv: More than 10% of 'Volume' values are zero or missing.\n",
      "2025-04-22 00:48:05,744 - WARNING - Skipping RSNHF.csv: At least one 'Adjusted Close' value is negative.\n",
      "2025-04-22 00:48:05,753 - WARNING - Skipping TRAUF.csv: More than 10% of 'Volume' values are zero or missing.\n",
      "2025-04-22 00:48:05,923 - WARNING - Skipping MRCR.csv: More than 10% of 'Volume' values are zero or missing.\n",
      "2025-04-22 00:48:05,923 - WARNING - Skipping MRCR.csv: More than 10% of 'Volume' values are zero or missing.\n",
      "2025-04-22 00:48:05,947 - WARNING - Skipping FMBM.csv: More than 10% of 'Volume' values are zero or missing.\n",
      "2025-04-22 00:48:05,947 - WARNING - Skipping FMBM.csv: More than 10% of 'Volume' values are zero or missing.\n",
      "2025-04-22 00:48:05,990 - WARNING - Skipping STZ-B.csv: More than 10% of 'Volume' values are zero or missing.\n",
      "2025-04-22 00:48:05,990 - WARNING - Skipping STZ-B.csv: More than 10% of 'Volume' values are zero or missing.\n",
      "2025-04-22 00:48:06,268 - WARNING - Skipping BSHI.csv: More than 10% of 'Volume' values are zero or missing.\n",
      "2025-04-22 00:48:06,268 - WARNING - Skipping BSHI.csv: More than 10% of 'Volume' values are zero or missing.\n",
      "2025-04-22 00:48:06,399 - WARNING - Skipping SONC.csv: More than 20% of 'Adjusted Close' values are zero or missing.\n",
      "2025-04-22 00:48:06,399 - WARNING - Skipping SONC.csv: More than 20% of 'Adjusted Close' values are zero or missing.\n",
      "2025-04-22 00:48:06,754 - WARNING - Skipping CPICQ.csv: More than 20% of 'Adjusted Close' values are zero or missing.\n",
      "2025-04-22 00:48:06,761 - WARNING - Skipping PNWRF.csv: More than 10% of 'Volume' values are zero or missing.\n",
      "2025-04-22 00:48:06,754 - WARNING - Skipping CPICQ.csv: More than 20% of 'Adjusted Close' values are zero or missing.\n",
      "2025-04-22 00:48:06,761 - WARNING - Skipping PNWRF.csv: More than 10% of 'Volume' values are zero or missing.\n",
      "2025-04-22 00:48:06,951 - WARNING - Skipping CNWT.csv: More than 10% of 'Volume' values are zero or missing.\n",
      "2025-04-22 00:48:06,951 - WARNING - Skipping CNWT.csv: More than 10% of 'Volume' values are zero or missing.\n",
      "2025-04-22 00:48:07,753 - INFO - Loaded and combined data from 376 files. Final shape: (4441, 2256)\n",
      "2025-04-22 00:48:07,753 - INFO - Loaded and combined data from 376 files. Final shape: (4441, 2256)\n"
     ]
    }
   ],
   "source": [
    "from ohlcv_data import OHLCVDataLoader\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "folder_path = \"/Users/elyazidbenkhadra/Downloads/stock_market_data/sp500/csv\"\n",
    "combined_data = OHLCVDataLoader.load_all_data(folder_path, clean=True, years=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7591befc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             CSCO_Low  CSCO_Open  CSCO_Volume  CSCO_High  CSCO_Close  \\\n",
      "Date                                                                   \n",
      "2005-04-25  17.389999  17.459999     39358000  17.600000   17.480000   \n",
      "2005-04-26  17.250000  17.350000     56444600  17.639999   17.280001   \n",
      "2005-04-27  17.080000  17.190001     62447400  17.459999   17.250000   \n",
      "2005-04-28  17.100000  17.139999     48957400  17.330000   17.139999   \n",
      "2005-04-29  17.040001  17.190001     49386700  17.299999   17.270000   \n",
      "\n",
      "            CSCO_Adjusted Close    UAL_Low  UAL_Open  UAL_Volume   UAL_High  \\\n",
      "Date                                                                          \n",
      "2005-04-25            12.413069  33.700001     34.82   1940300.0  34.939999   \n",
      "2005-04-26            12.271045  33.700001     34.82   1940300.0  34.939999   \n",
      "2005-04-27            12.249736  33.700001     34.82   1940300.0  34.939999   \n",
      "2005-04-28            12.171627  33.700001     34.82   1940300.0  34.939999   \n",
      "2005-04-29            12.263943  33.700001     34.82   1940300.0  34.939999   \n",
      "\n",
      "            ...  NWL_Volume  NWL_High  NWL_Close  NWL_Adjusted Close  \\\n",
      "Date        ...                                                        \n",
      "2005-04-25  ...     1205400     21.93  21.770000           12.459488   \n",
      "2005-04-26  ...     1937000     21.77  21.309999           12.196208   \n",
      "2005-04-27  ...     2085700     21.50  21.430000           12.264897   \n",
      "2005-04-28  ...     3127600     21.42  21.240000           12.156157   \n",
      "2005-04-29  ...     2705300     22.25  21.730000           12.436596   \n",
      "\n",
      "              BLK_Low   BLK_Open  BLK_Volume   BLK_High  BLK_Close  \\\n",
      "Date                                                                 \n",
      "2005-04-25  74.699997  75.150002      162600  76.160004  75.959999   \n",
      "2005-04-26  75.209999  76.000000      102200  76.730003  75.699997   \n",
      "2005-04-27  73.730003  75.519997      126000  75.519997  74.970001   \n",
      "2005-04-28  74.010002  74.970001      126300  75.250000  74.720001   \n",
      "2005-04-29  74.000000  74.900002      111900  75.070000  74.959999   \n",
      "\n",
      "            BLK_Adjusted Close  \n",
      "Date                            \n",
      "2005-04-25           50.192875  \n",
      "2005-04-26           50.021061  \n",
      "2005-04-27           49.538677  \n",
      "2005-04-28           49.373486  \n",
      "2005-04-29           49.532074  \n",
      "\n",
      "[5 rows x 2256 columns]\n"
     ]
    }
   ],
   "source": [
    "print(combined_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25a31adf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 376 columns ending with '_Adjusted Close'\n",
      "                    NaN Count Zero Count\n",
      "CSCO_Adjusted Close         0          0\n",
      "JPM_Adjusted Close          0          0\n",
      "MCK_Adjusted Close          0          0\n",
      "CNC_Adjusted Close          0          0\n",
      "COP_Adjusted Close          0          0\n",
      "...                       ...        ...\n",
      "KO_Adjusted Close           0          0\n",
      "IP_Adjusted Close           0          0\n",
      "ADSK_Adjusted Close         0          0\n",
      "ES_Adjusted Close           0          0\n",
      "BLK_Adjusted Close          0          0\n",
      "\n",
      "[376 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "adjusted_close_columns = [col for col in combined_data.columns if col.endswith('_Adjusted Close')]\n",
    "\n",
    "# Create a DataFrame to store the results\n",
    "nan_zero_counts = pd.DataFrame(index=adjusted_close_columns, columns=['NaN Count', 'Zero Count'])\n",
    "\n",
    "# Count NaN and zero values for each Adjusted Close column\n",
    "for column in adjusted_close_columns:\n",
    "    # Count NaN values\n",
    "    nan_count = combined_data[column].isna().sum()\n",
    "    # Count zero values (excluding NaN)\n",
    "    zero_count = (combined_data[column] == 0).sum()\n",
    "    \n",
    "    # Store in results DataFrame\n",
    "    nan_zero_counts.loc[column] = [nan_count, zero_count]\n",
    "\n",
    "# Sort by NaN count in descending order\n",
    "nan_zero_counts = nan_zero_counts.sort_values(by='NaN Count', ascending=False)\n",
    "\n",
    "print(f\"Found {len(adjusted_close_columns)} columns ending with '_Adjusted Close'\")\n",
    "print(nan_zero_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c0f3c5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No tickers with missing data found in the adjusted close columns.\n"
     ]
    }
   ],
   "source": [
    "def find_missing_data_tickers():\n",
    "    # Identify tickers with missing data in adjusted close columns\n",
    "    missing_data_tickers = []\n",
    "    \n",
    "    for column in adjusted_close_columns:\n",
    "        ticker = column.replace('_Adjusted Close', '')\n",
    "        # Check if there are any NaN values\n",
    "        if combined_data[column].isna().any():\n",
    "            missing_data_tickers.append(ticker)\n",
    "    \n",
    "    if missing_data_tickers:\n",
    "        print(f\"Found {len(missing_data_tickers)} tickers with missing data:\")\n",
    "        for ticker in missing_data_tickers:\n",
    "            print(f\"- {ticker}\")\n",
    "    else:\n",
    "        print(\"No tickers with missing data found in the adjusted close columns.\")\n",
    "\n",
    "# Run the function\n",
    "find_missing_data_tickers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b5413dd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining tickers after cleaning: 376\n",
      "Saved 376 tickers to tickers_list.csv\n",
      "Saved 376 tickers to tickers_list.csv\n"
     ]
    }
   ],
   "source": [
    "# Get list of tickers with missing data\n",
    "missing_data_tickers = []\n",
    "for column in adjusted_close_columns:\n",
    "    ticker = column.replace('_Adjusted Close', '')\n",
    "    if combined_data[column].isna().any():\n",
    "        missing_data_tickers.append(ticker)\n",
    "\n",
    "# Create a new DataFrame without columns from tickers with missing data\n",
    "clean_data = combined_data.copy()\n",
    "\n",
    "# Remove all columns related to problematic tickers\n",
    "for ticker in missing_data_tickers:\n",
    "    columns_to_drop = [col for col in clean_data.columns if col.startswith(f\"{ticker}_\")]\n",
    "    clean_data = clean_data.drop(columns=columns_to_drop)\n",
    "\n",
    "# Get the list of remaining tickers\n",
    "remaining_tickers = list(set([col.split('_')[0] for col in clean_data.columns if '_' in col]))\n",
    "print(f\"Remaining tickers after cleaning: {len(remaining_tickers)}\")\n",
    "\n",
    "# Export only the list of tickers as CSV\n",
    "tickers = [col.replace('_Adjusted Close','') for col in adjusted_close_columns]\n",
    "import pandas as pd\n",
    "pd.DataFrame({'ticker': tickers}).to_csv('tickers_list.csv', index=False)\n",
    "print(f'Saved {len(tickers)} tickers to tickers_list.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44ed602f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully saved to clean_sp500_data.csv\n",
      "File size: 152.33 MB\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Save the clean dataframe to CSV\n",
    "filename = 'clean_sp500_data.csv'\n",
    "clean_data.to_csv(filename)\n",
    "print(f\"Data successfully saved to {filename}\")\n",
    "\n",
    "# Check file size\n",
    "file_size_mb = os.path.getsize(filename) / (1024 * 1024)\n",
    "print(f\"File size: {file_size_mb:.2f} MB\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
