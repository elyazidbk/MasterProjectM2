{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "29fd658e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-21 15:02:02,181 - INFO - Loaded and combined data from 403 files. Final shape: (4442, 2418)\n"
     ]
    }
   ],
   "source": [
    "from ohlcv_data import OHLCVDataLoader\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "folder_path = \"/Users/elyazidbenkhadra/Downloads/stock_market_data/sp500/csv\"\n",
    "combined_data = OHLCVDataLoader.load_all_data(folder_path, clean=True, years=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7591befc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             CSCO_Low  CSCO_Open  CSCO_Volume  CSCO_High  CSCO_Close  \\\n",
      "Date                                                                   \n",
      "2005-04-22  17.219999  17.500000     41057800  17.610001   17.430000   \n",
      "2005-04-25  17.389999  17.459999     39358000  17.600000   17.480000   \n",
      "2005-04-26  17.250000  17.350000     56444600  17.639999   17.280001   \n",
      "2005-04-27  17.080000  17.190001     62447400  17.459999   17.250000   \n",
      "2005-04-28  17.100000  17.139999     48957400  17.330000   17.139999   \n",
      "\n",
      "            CSCO_Adjusted Close    UAL_Low  UAL_Open  UAL_Volume   UAL_High  \\\n",
      "Date                                                                          \n",
      "2005-04-22            12.377563  33.700001     34.82   1940300.0  34.939999   \n",
      "2005-04-25            12.413069  33.700001     34.82   1940300.0  34.939999   \n",
      "2005-04-26            12.271045  33.700001     34.82   1940300.0  34.939999   \n",
      "2005-04-27            12.249736  33.700001     34.82   1940300.0  34.939999   \n",
      "2005-04-28            12.171627  33.700001     34.82   1940300.0  34.939999   \n",
      "\n",
      "            ...  NWL_Volume  NWL_High  NWL_Close  NWL_Adjusted Close  \\\n",
      "Date        ...                                                        \n",
      "2005-04-22  ...     1190400     22.16  21.910000           12.539615   \n",
      "2005-04-25  ...     1205400     21.93  21.770000           12.459488   \n",
      "2005-04-26  ...     1937000     21.77  21.309999           12.196208   \n",
      "2005-04-27  ...     2085700     21.50  21.430000           12.264897   \n",
      "2005-04-28  ...     3127600     21.42  21.240000           12.156157   \n",
      "\n",
      "              BLK_Low   BLK_Open  BLK_Volume   BLK_High  BLK_Close  \\\n",
      "Date                                                                 \n",
      "2005-04-22  73.400002  73.629997      190800  76.000000  75.250000   \n",
      "2005-04-25  74.699997  75.150002      162600  76.160004  75.959999   \n",
      "2005-04-26  75.209999  76.000000      102200  76.730003  75.699997   \n",
      "2005-04-27  73.730003  75.519997      126000  75.519997  74.970001   \n",
      "2005-04-28  74.010002  74.970001      126300  75.250000  74.720001   \n",
      "\n",
      "            BLK_Adjusted Close  \n",
      "Date                            \n",
      "2005-04-22           49.723713  \n",
      "2005-04-25           50.192875  \n",
      "2005-04-26           50.021061  \n",
      "2005-04-27           49.538677  \n",
      "2005-04-28           49.373486  \n",
      "\n",
      "[5 rows x 2418 columns]\n"
     ]
    }
   ],
   "source": [
    "print(combined_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "25a31adf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 403 columns ending with '_Adjusted Close'\n",
      "                    NaN Count Zero Count\n",
      "CSCO_Adjusted Close         0          0\n",
      "ABT_Adjusted Close          0          0\n",
      "NTRR_Adjusted Close         0          0\n",
      "TXT_Adjusted Close          0          0\n",
      "MCK_Adjusted Close          0          0\n",
      "...                       ...        ...\n",
      "WDC_Adjusted Close          0          0\n",
      "PCAR_Adjusted Close         0          0\n",
      "KO_Adjusted Close           0          0\n",
      "IP_Adjusted Close           0          0\n",
      "BLK_Adjusted Close          0          0\n",
      "\n",
      "[403 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "adjusted_close_columns = [col for col in combined_data.columns if col.endswith('_Adjusted Close')]\n",
    "\n",
    "# Create a DataFrame to store the results\n",
    "nan_zero_counts = pd.DataFrame(index=adjusted_close_columns, columns=['NaN Count', 'Zero Count'])\n",
    "\n",
    "# Count NaN and zero values for each Adjusted Close column\n",
    "for column in adjusted_close_columns:\n",
    "    # Count NaN values\n",
    "    nan_count = combined_data[column].isna().sum()\n",
    "    # Count zero values (excluding NaN)\n",
    "    zero_count = (combined_data[column] == 0).sum()\n",
    "    \n",
    "    # Store in results DataFrame\n",
    "    nan_zero_counts.loc[column] = [nan_count, zero_count]\n",
    "\n",
    "# Sort by NaN count in descending order\n",
    "nan_zero_counts = nan_zero_counts.sort_values(by='NaN Count', ascending=False)\n",
    "\n",
    "print(f\"Found {len(adjusted_close_columns)} columns ending with '_Adjusted Close'\")\n",
    "print(nan_zero_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6c0f3c5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No tickers with missing data found in the adjusted close columns.\n"
     ]
    }
   ],
   "source": [
    "def find_missing_data_tickers():\n",
    "    # Identify tickers with missing data in adjusted close columns\n",
    "    missing_data_tickers = []\n",
    "    \n",
    "    for column in adjusted_close_columns:\n",
    "        ticker = column.replace('_Adjusted Close', '')\n",
    "        # Check if there are any NaN values\n",
    "        if combined_data[column].isna().any():\n",
    "            missing_data_tickers.append(ticker)\n",
    "    \n",
    "    if missing_data_tickers:\n",
    "        print(f\"Found {len(missing_data_tickers)} tickers with missing data:\")\n",
    "        for ticker in missing_data_tickers:\n",
    "            print(f\"- {ticker}\")\n",
    "    else:\n",
    "        print(\"No tickers with missing data found in the adjusted close columns.\")\n",
    "\n",
    "# Run the function\n",
    "find_missing_data_tickers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b5413dd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date\n",
      "2005-04-22   -0.0\n",
      "2005-04-25   -0.0\n",
      "2005-04-26   -0.0\n",
      "2005-04-27   -0.0\n",
      "2005-04-28   -0.0\n",
      "             ... \n",
      "2022-12-06    9.0\n",
      "2022-12-07    9.0\n",
      "2022-12-08    9.0\n",
      "2022-12-09    9.0\n",
      "2022-12-12    9.0\n",
      "Name: KACPF_Adjusted Close, Length: 4442, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(combined_data['KACPF_Adjusted Close'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
